{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Network Centrality in R\"\n",
        "author: \n",
        "  - name: David Schoch\n",
        "    orcid: 0000-0003-1689-0557\n",
        "    email: david.schoch@gesis.org\n",
        "    url: https://mr.schochastics.net\n",
        "    affiliations:\n",
        "      - name: GESIS - Leibniz Institute for the Social Sciences\n",
        "format:\n",
        "  html: default\n",
        "  ipynb: default\n",
        "license: CC BY-NC\n",
        "---\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will be able to\n",
        "\n",
        "1. Understand the ecosystem of R packages that provide centrality measurment tools.\n",
        "2. Use centrality indices confidently in your own projects.\n",
        "\n",
        "## Target audience\n",
        "\n",
        "e.g. This tutorial is aimed at beginners in network analysis with some knowledge in R.\n",
        "\n",
        "## Setting up the computational environment\n",
        "\n",
        "To run all the code in this tutorial, you need to install and load several packages.\n",
        "```{r install_libraries,eval=FALSE}\n",
        "install.packages(c(\"igraph\", \"netrankr\", \"centiserve\",\"sna\",\"expm\"))\n",
        "```\n",
        "\n",
        "```{r loadlibs}\n",
        "library(netrankr)\n",
        "library(igraph)\n",
        "```\n",
        "\n",
        "## Social Science Usecase(s)\n",
        "\n",
        "Network centrality allows to pinpoint influential or strategically positioned individuals within a social network, offering insights into power dynamics, information flow, and social influence. For example, in studying the spread of health-related information on a platform like Twitter, researchers could use centrality metrics to identify which users are most crucial in disseminating information about a public health campaign. Degree centrality can reveal which individuals have the highest number of direct connections, suggesting they are well-positioned to rapidly broadcast messages. Betweenness centrality highlights users who act as bridges between different groups, making them pivotal for connecting otherwise separate sub-communities and potentially influencing diverse audiences. Closeness centrality identifies individuals who can quickly access or share information throughout the network, often making them efficient distributors of critical updates. By examining these metrics, one can identify not only the main influencers in a network but also potential \"gatekeepers\" or \"brokers\" who control or facilitate the flow of information, which is particularly valuable for understanding and optimizing the spread of public health messages or assessing the reach and impact of digital campaigns.\n",
        "\n",
        "\n",
        "# Part 1\n",
        "## Introduction\n",
        "\n",
        "One of the many tools to analyze networks are measures of *centrality*. \n",
        "In a nutshell, a measure of centrality is an index that assigns a numeric values to\n",
        "the nodes of the network. The higher the value, the more central the node. \n",
        "\n",
        "## R packages for centrality\n",
        "\n",
        "(*This section lists a great variety of different indices. If you are interested in the technical details,\n",
        "consult the help of the function and check out the references*)\n",
        "\n",
        "There are several packages that implement centrality indices for R. \n",
        "Of course, there are the big network and graph packages such as\n",
        "`igraph`,`sna`, `qgraph`, and `tidygraph`, which are designed as general purpose packages \n",
        "for network analysis. Hence, they also implement some centrality indices.\n",
        "\n",
        "`igraph` contains the following 10 indices:\n",
        "\n",
        "- degree (`degree()`)\n",
        "- weighted degree (`graph.strength()`)\n",
        "- betweenness (`betweenness()`)\n",
        "- closeness (`closeness()`)\n",
        "- eigenvector (`eigen_centrality()`)\n",
        "- alpha centrality (`alpha_centrality()`)\n",
        "- power centrality (`power_centrality()`)\n",
        "- PageRank (`page_rank()`)\n",
        "- eccentricity (`eccentricity()`)\n",
        "- hubs and authorities (`authority_score()` and `hub_score()`)\n",
        "- subgraph centrality (`subgraph_centrality()`)\n",
        "\n",
        "In most cases, parameters can be adjusted to account for directed/undirected and \n",
        "weighted/unweighted networks.\n",
        "\n",
        "The `sna` package implements roughly the same indices together with:\n",
        "\n",
        "- flow betweenness (`flowbet()`)\n",
        "- load centrality (`loadcent()`)\n",
        "- Gil-Schmidt Power Index (`gilschmidt()`)\n",
        "- information centrality (`infocent()`)\n",
        "- stress centrality (`stresscent()`)\n",
        "\n",
        "`qgraph` specializes on weighted networks. It has a generic function `centrality_auto()`\n",
        "which returns, depending on the network, the following indices:\n",
        "\n",
        "- degree\n",
        "- strength (weighted degree)\n",
        "- betweenness\n",
        "- closeness\n",
        "\n",
        "The package also contains the function `centrality()`, which calculates a non-linear combination\n",
        "of unweighted and weighted indices using a tuning parameter $\\alpha$ (See [Opsahl et al.](https://www.sciencedirect.com/science/article/pii/S0378873310000183)). \n",
        "\n",
        "There are also some dedicated centrality packages, such as `centiserve`, `CINNA`, `influenceR` and `keyplayer`.\n",
        "The biggest in terms of implemented indices is currently `centiserve` with a total of 33 indices.\n",
        "\n",
        "The package is maintained by the team behind [centiserver](http://www.centiserver.org/),\n",
        "the \"comprehensive centrality resource and server for centralities calculation\".\n",
        "The website collects indices found in the literature. Currently (April 2023), it lists 403 different indices.\n",
        "\n",
        "`CINNA` is a fairly new package. The package description says\n",
        "\"Functions for computing, comparing and demonstrating top informative centrality measures within a network.\"\n",
        "Most of the indices in the package are imported from other package, such as `centiserve`.\n",
        "In addition, there are:\n",
        "\n",
        "- Dangalchev closeness (`dangalchev_closeness_centrality()`)\n",
        "- group centrality (`group_centrality()`)\n",
        "- harmonic closeness (`harmonic_centrality()`)\n",
        "- local bridging centrality (`local_bridging_centrality()`)\n",
        "\n",
        "The function `calculate_centralities()` can be used to calculate all applicable indices\n",
        "to a network. The primary purpose of the package is to facilitate the choice of indices\n",
        "by visual and statistical tools. If you are interested in the details, see this [tutorial](https://www.datacamp.com/community/tutorials/centrality-network-analysis-R)\n",
        "and this [vignette](https://cran.r-project.org/web/packages/CINNA/vignettes/CINNA.html).\n",
        "\n",
        "`influenceR` and `keyplayer` are comparably small packages which implement only a small\n",
        "number of indices.\n",
        "\n",
        "*(For now, I deliberately leave out my package `netrankr`. While it implements a great variety of indices,\n",
        "it is not its primary purpose to provide a set of predefined measures. We will come to that in\n",
        "the next part.)*\n",
        "\n",
        "## A small example\n",
        "\n",
        "Let us start with a fairly simple example. Consider the following two small networks.\n",
        "\n",
        "```{r loadexamples}\n",
        "#data can be found here: https://github.com/schochastics/centrality\n",
        "g1 <- readRDS(\"example_1.rds\")\n",
        "g2 <- readRDS(\"example_2.rds\")\n",
        "```\n",
        "\n",
        "![](example.png)\n",
        "\n",
        "\n",
        "Now, without any empirical context, we want to determine the most central node in both networks.\n",
        "I wrote a small function which calculates 35 of the above mentioned\n",
        "indices. \n",
        "```{r helper}\n",
        "require(expm)\n",
        "all_indices <- function(g){\n",
        "  res <- matrix(0,vcount(g),35)\n",
        "  res[,1] <- igraph::degree(g)\n",
        "  res[,2] <- igraph::betweenness(g)\n",
        "  res[,3] <- igraph::closeness(g)\n",
        "  res[,4] <- igraph::eigen_centrality(g)$vector\n",
        "  res[,5] <- 1/igraph::eccentricity(g)\n",
        "  res[,6] <- igraph::subgraph_centrality(g)\n",
        "  \n",
        "  A <- get.adjacency(g,sparse=F)\n",
        "  res[,7] <- sna::flowbet(A)\n",
        "  res[,8] <- sna::loadcent(A)\n",
        "  res[,9] <- sna::gilschmidt(A)\n",
        "  res[,10] <- sna::infocent(A)\n",
        "  res[,11] <- sna::stresscent(A)\n",
        "  \n",
        "  res[,12] <- 1/centiserve::averagedis(g)\n",
        "  res[,13] <- centiserve::barycenter(g)\n",
        "  res[,14] <- centiserve::closeness.currentflow(g)\n",
        "  res[,15] <- centiserve::closeness.latora(g)\n",
        "  res[,16] <- centiserve::closeness.residual(g)\n",
        "  res[,17] <- centiserve::communibet(g)\n",
        "  res[,18] <- centiserve::crossclique(g)\n",
        "  res[,19] <- centiserve::decay(g)\n",
        "  res[,20] <- centiserve::diffusion.degree(g)     \n",
        "  res[,21] <- 1/centiserve::entropy(g)\n",
        "  res[,22] <- centiserve::geokpath(g)\n",
        "  res[,23] <- centiserve::katzcent(g)             \n",
        "  res[,24] <- centiserve::laplacian(g)\n",
        "  res[,25] <- centiserve::leverage(g)             \n",
        "  res[,26] <- centiserve::lincent(g)\n",
        "  res[,27] <- centiserve::lobby(g)\n",
        "  res[,28] <- centiserve::markovcent(g)           \n",
        "  res[,29] <- centiserve::mnc(g)\n",
        "  res[,30] <- centiserve::radiality(g)            \n",
        "  res[,31] <- centiserve::semilocal(g)\n",
        "  res[,32] <- 1/centiserve::topocoefficient(g) \n",
        "\n",
        "  res[,33] <- CINNA::dangalchev_closeness_centrality(g)\n",
        "  res[,34] <- CINNA::harmonic_centrality(g)\n",
        "  res[,35] <- 1/CINNA::local_bridging_centrality(g)\n",
        "  apply(res,2,function(x) round(x,8))\n",
        "}\n",
        "```\n",
        "We blindly apply them to both networks and see what happens.\n",
        "\n",
        "```{r examplecalc}\n",
        "res1 <- all_indices(g1)\n",
        "res2 <- all_indices(g2)\n",
        "```\n",
        "\n",
        "The chart below shows a breakdown for how many indices return a specific node as the most central one.\n",
        "\n",
        "![](most_central.png)\n",
        "\n",
        "In network 1, five different nodes are considered to be \"the most central node\" by different\n",
        "indices. In network 2, on the other hand, all 35 indices agree on node eleven as the most\n",
        "central one. The take away message from network 1 is clearly that choice matters.\n",
        "Depending on which index we choose, we can obtain very different results. Network 2 paints a completely different picture. \n",
        "All indices agree upon the most central node. Even better (or worse?), they all\n",
        "induce the same ranking. We can check that with the function `compare_ranks()` in\n",
        "the `netrankr` package by counting the wrongly ordered (discordant) pairs of nodes for pairs of indices $x$ and $y$.\n",
        "That is, $x$ ranks a node $i$ before $j$ but $y$ ranks $j$ before $i$.\n",
        "\n",
        "```{r ordering2}\n",
        "discordant <- rep(1,35*34)\n",
        "k <- 0\n",
        "for(i in 1:(ncol(res2)-1)){\n",
        "  for(j in (i=1):ncol(res2)){\n",
        "    k <- k+1\n",
        "    discordant[k] <- compare_ranks(res2[,i],res2[,j])$discordant\n",
        "  }\n",
        "}\n",
        "any(discordant>0)\n",
        "```\n",
        "So, the indices not only agree upon the most central node, but also on the rest of the ranking!\n",
        "\n",
        "You may be wondering, why we are only looking at the ranking and not the actual values. \n",
        "Effectively, the values themselves don't have any meaning. There is no such thing as\n",
        "a \"unit of centrality\", if we look at it from a measurement perspective. For instance, we can't say that\n",
        "a node is \"twice as between\" as another if its betweenness value is twice as high. Centrality\n",
        "should thus not be considered to be on an interval scale, but rather an ordinal one.\n",
        "This might seem like a restriction at first, but we will see later on that it facilitates\n",
        "many theoretical examinations.\n",
        "\n",
        "The two networks illustrate the big problem of choice. We have \"only\" tried 35 different\n",
        "indices, so we actually can't make any conclusive statements about central nodes. \n",
        "After all, 35 indices can in the best case produce 35 completely different rankings. \n",
        "But theoretically, there are $11! =$ `r format(factorial(11),big.mark=\",\")` possibilities \n",
        "to rank the nodes of the network without allowing ties, which indices actually do. \n",
        "So, what if we missed hundreds of thousands of potential indices that would rank, say, \n",
        "node nine on top for network 1? What if those 35 indices are exactly the ones \n",
        "that rank node eleven on top for network 2, but no other index does that? \n",
        "\n",
        "In the next example, we add some (made up) empirical context to illustrate the \n",
        "problem of how to validate the appropriateness of chosen indices.\n",
        "\n",
        "## An almost realistic example\n",
        "\n",
        "Centrality indices are commonly used as an explanatory variable for some observed\n",
        "phenomenon or node attribute in a network. Let's say we have the following abstract research question.\n",
        "Given a network where each node is equipped with a binary attribute, which could\n",
        "signify the presence or absence of some property. Can a centrality index \"explain\" the presence\n",
        "of this attribute?\n",
        "\n",
        "```{r loadexamplebig}\n",
        "# data can be found here: https://github.com/schochastics/centrality\n",
        "g3 <- readRDS(\"example_3.rds\")\n",
        "```\n",
        "\n",
        "![](example_big.png)\n",
        "\n",
        "Instead of 35 indices, we here focus on the more common indices.\n",
        "\n",
        "```{r loadcent}\n",
        "#| eval: false\n",
        "cent <- data.frame(nodes=1:vcount(g3),attr=V(g3)$attr)\n",
        "cent$degree <- igraph::degree(g3)\n",
        "cent$betweenness <- igraph::betweenness(g3)\n",
        "cent$closeness <- igraph::closeness(g3)\n",
        "cent$eigen <- igraph::eigen_centrality(g3)$vector\n",
        "cent$subgraph <- igraph::subgraph_centrality(g3)\n",
        "cent$infocent <- sna::infocent(as_adj(g3,sparse=F))\n",
        "```\n",
        "\n",
        "If we postulate that one of the indices is somehow related with the attribute, then \n",
        "we should see that nodes with the attribute should tend to be ranked on top of the induced ranking.\n",
        "The below bar chart shows the number of nodes having the attribute that are ranked in\n",
        "the top 150 for each index.\n",
        "\n",
        "![](attr150.png)\n",
        "\n",
        "According to this evaluation, subgraph centrality is best in \"explaining\"\n",
        "the node attribute. But how conclusive is this now? Note that we did not specify any \n",
        "real hypothesis so basically any index could be a valid choice. Instead of\n",
        "trying out one of the other mentioned ones though, we now try to design a new index\n",
        "which hopefully gives us an even better \"fit\". After some wild math, we may end up with something like this:\n",
        "\n",
        "$$\n",
        "c(u)= ccoef(u) \\left[\\sum\\limits_{v \\in N(u)} \\sum\\limits_{k=0}^{\\infty} \\frac{(A^{[u]})_{vv}^{2k}}{(2k)!} \\right]\n",
        "$$\n",
        "Ok, so what is happening here? $ccoef(u)$ is the clustering coefficient of the node $u$ (`igraph::transitivity(g,type=\"local\")`). The first sum is over all neighbors $v$ of $u$. The second sum is used to sum up all closed walks of even length weighted by the inverse factorial of the length.\n",
        "\n",
        "We can directly invent a second one, based on the walks of odd length.\n",
        "$$\n",
        "c(u)= ccoef(u) \\left[\\sum\\limits_{v \\in N(u)} \\sum\\limits_{k=0}^{\\infty} \\frac{(A^{[u]})_{vv}^{2k+1}}{(2k+1)!} \\right]\n",
        "$$\n",
        "Mathematically fascinating, yet both indices defy any rational meaning. \n",
        "\n",
        "Both indices have not yet been considered in the literature except in a [PhD thesis](http://kops.uni-konstanz.de/bitstream/handle/123456789/34821/Schoch_0-347789.pdf?sequence=3&isAllowed=y). \n",
        "The indices are implemented in `netrankr` as the *hyperbolic index*.\n",
        "```{r example3hyp}\n",
        "#| eval: false\n",
        "cent$hyp_eve <- hyperbolic_index(g3,type = \"even\")\n",
        "cent$hyp_odd <- hyperbolic_index(g3,type = \"odd\")\n",
        "```\n",
        "\n",
        "How do they compare to the other indices?\n",
        "\n",
        "![](attr150_hyp.png)\n",
        "\n",
        "Both indices are far superior. Around 66% of the top 150 nodes are equipped\n",
        "with the attribute, compared to 50% for subgraph centrality. \n",
        "\n",
        "\n",
        "Obviously, this was a very contrived example, yet it emphasizes some important points.\n",
        "First, it is relatively easy to design an index that gives you the results you intend to get and hence\n",
        "justify the importance of the index. Second, you can never be sure, though, that you found \"the best\" index for the task. There may well be some even more obscure index that gives you better results. Third, if you do not find a fitting index, you can not be sure that there does not exist one after all. \n",
        "\n",
        "## Summary\n",
        "\n",
        "The examples were intended to highlight some of the problems that you may encounter when \n",
        "using centrality indices and how hard it is to navigate the index landscape, keeping up with all\n",
        "the newly designed ones. \n",
        "\n",
        "One is therefore all to often tempted to go down the data-minning road.\n",
        "That is, take a handfull of indices, check what works best and come up with a post-hoc\n",
        "explanation as to why the choice was reasonable. Note, though, that this approach is not \n",
        "universally bad, or wrong. It mainly depends on what you your intentions are. \n",
        "You simply want to have a sort of predictive model? Go wild on the indices and maximize! \n",
        "The `CINNA` package offers some excellent tools for that.\n",
        "\n",
        "However, if you are working in a theory-heavy area, then this approach is not for you.\n",
        "\"Trial-and-Error\" approaches are hardly appropriate to test theories.\n",
        "But how can we properly test a hypothesis with measures of centrality, when obviously\n",
        "there is very little agreement in the proper procedure for centrality measurement? \n",
        "\n",
        "In the upcoming sections, we discuss a different approach to centrality, which may help\n",
        "in translating a theoretical construct into a measure of centrality. \n",
        "\n",
        "# Part 2\n",
        "\n",
        "## Introduction\n",
        "\n",
        "When looking at the vast amount of indices, it may be reasonable to ask if there is any \n",
        "natural limit for what can be considered a centrality index. Concretely, are there any\n",
        "theoretical properties that an index has to have in order to be called a centrality index?\n",
        "There exist several axiomatic systems for centrality, which define some desirable properties\n",
        "that a proper index should have. While these systems are able to shed some light on specific \n",
        "groups of indices, they are in most cases not comprehensive. That is, it is often possible\n",
        "to construct counterexamples for most indices such that they do not fulfill the properties.\n",
        "Instead of the rather normative axiomatic approach, we explore a more descriptive\n",
        "approach. We will address the following questions:\n",
        "\n",
        "- Are there any properties that are shared by all (or almost all) indices?\n",
        "- If so, can they be exploited for a different kind of centrality analysis?\n",
        "\n",
        "## Neighborhood-inclusion\n",
        "\n",
        "In the first post, we examined the following two small examples.\n",
        "```{r loadexamples1}\n",
        "#| eval: false\n",
        "#data can be found here: https://github.com/schochastics/centrality\n",
        "g1 <- readRDS(\"example_1.rds\")\n",
        "g2 <- readRDS(\"example_2.rds\")\n",
        "```\n",
        "\n",
        "![](example.png)\n",
        "\n",
        "It turned out that for network 1, 35 indices gave very different results and for network 2\n",
        "they all coincided. In the following, we discuss why this is the case.\n",
        "\n",
        "It turns out that there actually is a very intuitive structural property that underlies many centrality indices.\n",
        "If a node has exactly the same neighbors as another and potentially some more, it will\n",
        "never be less central, independent of the choice of index. Formally,\n",
        "$$\n",
        "N(i) \\subseteq N[j] \\implies c(i) \\leq c(j)\n",
        "$$\n",
        "for centrality indices $c$. This property is called *neighborhood-inclusion*.\n",
        "\n",
        "An illustration is given below.\n",
        "![](neighborhood_inclusion.png\")\n",
        "\n",
        "Node $i$ and $j$ have three common neighbors (the black nodes), but $j$ has two additional neighbors\n",
        "(the grey nodes), hence $i$'s neighborhood is included in the neighborhood of $j$. Note that\n",
        "the inclusion is actually defined for the closed neighborhood ($N[j]=N(j) \\cup \\{j\\}$). This is due to some \n",
        "mathematical peculiarities when $i$ and $j$ are connected. Neighborhood-inclusion defines a\n",
        "partial ranking of the nodes. That is, some node pairs will not be comparable, because neither\n",
        "$N(i) \\subseteq N[j]$ nor $N(j) \\subseteq N[i]$ will hold. If the neighborhood of a node $i$\n",
        "is properly contained in the neighborhood of $j$, then we will say that $i$ is *dominated* by $j$.\n",
        "\n",
        "We can calculate all pairs of neighborhood-inclusion with the function `neighborhood_inclusion()`\n",
        "in the `netrankr` package.\n",
        "```{r ni_examples}\n",
        "P1 <- neighborhood_inclusion(g1)\n",
        "P2 <- neighborhood_inclusion(g2)\n",
        "```\n",
        "\n",
        "An entry $P[i,j]$ is one if $N(i)\\subseteq N[j]$ and zero otherwise. With the function \n",
        "`comparable_pairs()`, we can check the fraction of comparable pairs. Let us start with the first network.\n",
        "\n",
        "```{r comparable_example}\n",
        "comparable_pairs(P1)\n",
        "```\n",
        "\n",
        "Only `r round(netrankr::comparable_pairs(P1)*100)`% of pairs are comparable with\n",
        "neighborhood-inclusion. For a better understanding of the dominance relations, we can also visualize \n",
        "them as a graph.\n",
        "```{r dom_graph1}\n",
        "d1 <- dominance_graph(P1)\n",
        "```\n",
        "\n",
        "![](dominance1.png)\n",
        "\n",
        "An edge $(i,j)$ is present, if $P[i,j]=1$ and thus $i$ is dominated by $j$.\n",
        "Centrality indices will always put these comparable pairs in the same order.\n",
        "To check this, we use the `all_indices()` function from the last post again.\n",
        "```{r indices_ex1}\n",
        "res <- all_indices(g1)\n",
        "```\n",
        "Let us focus on the triple $1,3,5$.\n",
        "```{r triplet135}\n",
        "P1[c(1,3,5),c(1,3,5)] #(compare also with the dominance graph)\n",
        "```\n",
        "So, indices should rank them as $1\\leq3\\leq 5$.\n",
        "```{r ranks135}\n",
        "ranks135 <- apply(res[c(1,3,5),],2,rank)\n",
        "rownames(ranks135) <- c(1,3,5)\n",
        "ranks135\n",
        "```\n",
        "All 35 indices indeed produce a ranking that is in accordance with what we postulated.\n",
        "(Ties are allowed in the ranking since we require \"$\\leq$\" and not \"$<$\" ).\n",
        "\n",
        "The `is_preserved()` function can be used to check if all dominance relations are \n",
        "preserved in the index induced rankings.\n",
        "```{r preserved35}\n",
        "apply(res,2, function(x) is_preserved(P1,x))\n",
        "```\n",
        "\n",
        "For the other `r 100-round(netrankr::comparable_pairs(P1)*100)`% of pairs that are not comparable by\n",
        "neighborhood-inclusion, indices are \"at liberty\" to rank nodes differently. \n",
        "Take the triple $6,7,8$ as an example.\n",
        "```{r triplet678}\n",
        "P1[6:8,6:8] #(compare also with the dominance graph)\n",
        "```\n",
        "\n",
        "```{r ranks678}\n",
        "ranks678 <- apply(res[6:8,],2,rank)\n",
        "rownames(ranks678) <- 6:8\n",
        "# unique rankings of 6,7,8\n",
        "ranks678[,!duplicated(t(ranks678))]\n",
        "```\n",
        "The 35 indices produce 8 distinct rankings of $6,7,8$. This means that whenever a \n",
        "pair of nodes $i$ and $j$ are not comparable with neighborhood-inclusion, it is (theoretically)\n",
        "possible to construct an index for each of the three possible rankings ($i<j$, $j<i$, $i\\sim j$)\n",
        "\n",
        "Moving on to the second network.\n",
        "```{r comparable2}\n",
        "comparable_pairs(P2)\n",
        "```\n",
        "So all pairs are comparable by neighborhood-inclusion. Hence, all indices will\n",
        "induce the same ranking (up to some potential tied ranks, but no discordant pairs), as\n",
        "we already observed in the previous post.\n",
        "\n",
        "## Threshold graphs and correlation among indices\n",
        "\n",
        "The second example network is part of the class of *threshold graphs*. One of their\n",
        "defining features is that the partial ranking induced by neighborhood-inclusion is in fact\n",
        "a ranking. A random threshold graph can be created with the `threshold_graph()` function.\n",
        "The function takes two parameters, one for the number of nodes, and one (approximately) for\n",
        "the density. The class includes some well known graphs, such as complete graphs or star graphs.\n",
        "\n",
        "We know from the previous section that centrality indices will always produce the same ranking\n",
        "on these graphs. This allows us to reason about another topic that is frequently investigated: \n",
        "correlations among indices. Correlations are often attributed to the definitions of indices.\n",
        "Take closeness and betweenness. On first glance, they measure very different things: Being close to all nodes and being \"in between\" all nodes. Hence, we would expect them to be only weakly correlated. But threshold graphs give us a reason to believe, that correlations are not entirely dependent on the definitions but rather on structural features of the network. ([This article](https://www.sciencedirect.com/science/article/pii/S0378873316303690) gives more details and references on that topic).\n",
        "\n",
        "As an illustration, we compare betweenness and closeness on a threshold graph and a threshold graph with\n",
        "added noise from a random graph.\n",
        "```{r tg_noise}\n",
        "#threshold graph\n",
        "tg3 <- threshold_graph(100,0.2)\n",
        "#noise graph\n",
        "gnp <- sample_gnp(100,0.01,directed = FALSE)\n",
        "A1 <- get.adjacency(tg3,sparse=FALSE)\n",
        "A2 <- get.adjacency(gnp,sparse=FALSE)\n",
        "\n",
        "#construct a noise threshold graph\n",
        "tg3_noise <- graph_from_adjacency_matrix(xor(A1,A2),mode = \"undirected\")\n",
        "\n",
        "#calculate discordant pairs for betweenness and closeness in both networks\n",
        "disc1 <- compare_ranks(betweenness(tg3),closeness(tg3))$discordant\n",
        "disc2 <- compare_ranks(betweenness(tg3_noise),closeness(tg3_noise))$discordant\n",
        "c(disc1,disc2)\n",
        "```\n",
        "On the threshold graph we do not observe any discordant pairs for the two indices. However, the little noise we added to the threshold graph was enough to introduce `r disc2` pairs of nodes that are now ranked differently. \n",
        "In general, we can say that\n",
        "\n",
        "*The closer a network is to be a threshold graph, the higher we expect the correlation of any pair of centrality indices to be, independent of their definition.*\n",
        "\n",
        "But how to define *being close* to a threshold graph? One obvious choice is to \n",
        "use the function `comparable_pairs()`. The more pairs are comparable, the less possibilities\n",
        "for indices to rank the nodes differently. Hence, we are close to a unique ranking obtained \n",
        "for threshold graphs. A second option is to use an appropriate distance measure for graphs.\n",
        "`netrankr` implements the so called *majorization gap* which operates on the degree sequences of graphs.\n",
        "In its essence, it returns the number of edges that need to be rewired, in order to turn an \n",
        "arbitrary graph into a threshold graph.\n",
        "\n",
        "```{r major}\n",
        "mg1 <- majorization_gap(tg3)\n",
        "mg2 <- majorization_gap(tg3_noise)\n",
        "c(mg1,mg2)\n",
        "```\n",
        "\n",
        "The result is given as a fraction of the total number of edges. So `r round(mg2*100)`%\n",
        "of edges need to be rewired in the noisy graph to turn it into a threshold graph.\n",
        "To get the raw count, set `norm=FALSE`.\n",
        "\n",
        "```{r major_raw}\n",
        "majorization_gap(tg3_noise,norm = FALSE)\n",
        "```\n",
        "\n",
        "\n",
        "## Summary\n",
        "\n",
        "Neighborhood-inclusion seems to be a property that underlies many centrality indices.\n",
        "If a node $i$ is dominated by another node $j$, then (almost) any index will rank $j$\n",
        "higher than $i$. I am not going to make the bold statement of saying that **all** centrality indices\n",
        "have this property, although all commonly used and traditional indices have this property. However, it is easy to come up with an index that doesn't preserve the partial ranking (Coincidentally, the two hyperbolic indices from the first post don't preserve it. Thank god!). But if we accept the preservation of neighborhood-inclusion to be a defining property of\n",
        "centrality indices, then we are able to a) derive more theoretical results about centrality (see correlation section)\n",
        "b) distinguish proper indices from invalid ones (see hyperbolic indices)\n",
        "and c) think about new ways of assessing centrality, that do not necessarily rely on indices.\n",
        "\n",
        "Point c) will be partially addressed in the next post and in more detail in subsequent ones.  \n",
        "The main focus for the next post is on how to extend neighborhood-inclusion to other forms of dominance.\n",
        "Additionally, we will see how to deconstruct indices into a series of building blocks, \n",
        "which allows for a deeper understanding on what indices actually \"measure\".\n",
        "\n",
        "# Part 3\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Neighborhood-inclusion seems to underlie many different centrality indices and as such\n",
        "serves (or better: could serve) as a defining property of a centrality index. That is:\n",
        "\n",
        ">An index is a measure of centrality if and only if it preserves the partial ranking induced by neighborhood-inclusion\n",
        "\n",
        "While this gives as a theoretical basis for centrality, it comes with a bit of problem.\n",
        "Namely, that we do not expect many comparable pairs in (large) real-world networks.\n",
        "Take the third example network from the first post.\n",
        "\n",
        "```{r gni1}\n",
        "g3 <- readRDS(\"example_3.rds\")\n",
        "P <- neighborhood_inclusion(g3)\n",
        "comparable_pairs(P)\n",
        "```\n",
        "\n",
        "\n",
        "Only `r round(netrankr::comparable_pairs(P)*100,1)`% of pairs are comparable. This means that\n",
        "centrality indices are at liberty to rank 99.4% of pairs in any order. So, neighborhood-inclusion\n",
        "may not be very restrictive in large networks. This is much like with *structural equivalence*. \n",
        "It is a very intuitive concept for equivalences in networks (having exactly the same neighbors), however we do not expect many equivalent pairs in large networks. This does not render the concept useless, but requires some relaxations. \n",
        "\n",
        "In the following, we introduce dominance relations, which incrementally extend the \n",
        "partial ranking of neighborhood-inclusion and thus tighten the partial ranking\n",
        "that indices preserve. We start by illustrating how indices can be decomposed into a series \n",
        "of building blocks.\n",
        "\n",
        "## Deconstructing Indices\n",
        "\n",
        "Centrality indices assess structural importance based on a great variety of different\n",
        "graph theoretic notions, like shortest paths (closeness) or walks (subgraph centrality).\n",
        "Implicitly, though, they all follow a simple recipe:\n",
        "\n",
        "- derive an indirect relation\n",
        "- aggregate the indirect relations\n",
        "\n",
        "As mentioned above, indirect relation are commonly derived via graph trajectories such as paths\n",
        "and walks, for instance to compute distances. The aggregation is usually a simple summation of all relations of a node, but others are \n",
        "possible too (e.g. $\\max$ as in eccentricity). In its most generic form, we can thus write a centrality index as\n",
        "$$\n",
        "c(i)= \\sum_j \\tau(x)_{ij}\n",
        "$$\n",
        "where $x$ are the observed relations (basically the adjacency matrix) and $\\tau$\n",
        "a generic transformation function. Replacing $\\tau$ with $id$, we obtain degree centrality \n",
        "and setting $\\tau=dist$, we obtain closeness. A suitable function $\\tau$ can be\n",
        "defined for all centrality indices, such that any index can basically be seen as degree in an\n",
        "appropriately transformed network. \n",
        "\n",
        "The package `netrankr` provides a set of 24 different indirect relations that can be used\n",
        "to construct indices. A few common examples are given below.\n",
        "```{r indices}\n",
        "#| eval: false\n",
        "#closeness \n",
        "g |> \n",
        "  indirect_relations(type='dist_sp') |> \n",
        "  aggregate_positions(type='invsum')\n",
        "  \n",
        "#betweenness\n",
        "g |> \n",
        "  indirect_relations(type='depend_sp') |> \n",
        "  aggregate_positions(type='sum')\n",
        "  \n",
        "#eigenvector\n",
        "g |> \n",
        "  indirect_relations(type='walks',FUN=walks_limit_prop) |> \n",
        "  aggregate_positions(type='sum')\n",
        "\n",
        "#subgraph \n",
        "g |> \n",
        "  indirect_relations(type='walks',FUN=walks_exp) |> \n",
        "  aggregate_positions(type='self')\n",
        "```\n",
        "Consult the help for `indirect_relations()` to see all options.  \n",
        "Note that we make use of the `|>` operator. This should appeal to the recipe \n",
        "idea from above: `network |> indirect_relation |> aggregation` (but requires R Version >4.0). The package also\n",
        "includes a handy RStudio addin, which can be used to build the pipelines more easily. \n",
        "\n",
        "Defining indices in this way is certainly more cumbersome than using, say, `betweennes(g)`.\n",
        "However, it allows us to intervene at any step and *do something else*.\n",
        "\n",
        "## Extended Dominance Relations\n",
        "\n",
        "To illustrate the \"something else\", we look at our first small example network again.\n",
        "\n",
        "```{r loadexamples2}\n",
        "g1 <- readRDS(\"example_1.rds\")\n",
        "```\n",
        "\n",
        "Following the recipe, you have decided, that the *relations of interest* for your analysis\n",
        "are the distances between nodes. The problem is, aggregating them into an index can still\n",
        "be done in various ways. Three distance based centrality examples are shown below.\n",
        "\n",
        "```{r distance_based}\n",
        "#classic closeness\n",
        "c_C <- g1 |> \n",
        "  indirect_relations(type=\"dist_sp\") |> \n",
        "  aggregate_positions(type=\"invsum\")\n",
        "\n",
        "#harmonic closeness\n",
        "c_HC <- g1 |> \n",
        "  indirect_relations(type=\"dist_sp\",FUN=dist_inv) |> \n",
        "  aggregate_positions(type=\"sum\")\n",
        "\n",
        "#residual-type closeness\n",
        "c_RC <- g1 |> \n",
        "  indirect_relations(type=\"dist_sp\",FUN=dist_2pow) |> \n",
        "  aggregate_positions(type=\"sum\")\n",
        "\n",
        "```\n",
        "\n",
        "Any of the above indices starts with the derivation of distances, but then proceeds with\n",
        "a different form of aggregation:\n",
        "$$\n",
        "c_C(i)=\\frac{1}{\\sum dist(i,j)},\\quad c_{HC}(i)=\\sum\\frac{1}{dist(i,j)}, \\quad c_{RC}(i)=\\sum 2^{-dist(i,j)}\n",
        "$$\n",
        "Possibilities are virtually endless for aggregating distances into an index.\n",
        "From the previous part, we know that any of these indices preserve neighborhood-inclusion.\n",
        "Once we have settled for a relation, as in this case, we can extend the partial ranking\n",
        "using the following considerations: If a $dist(i,k)$ is larger than $dist(j,k)$ for all\n",
        "nodes $k$, then no matter how we aggregate the relations (as long as it is monotonic),\n",
        "$i$ will always be less central then $j$. With a bit more formalism:\n",
        "$$\n",
        "dist(i,k) \\geq dist(j,k) \\text{ for all } k \\implies c_x(i)\\leq c_x(j)\n",
        "$$\n",
        "where $c_x$ is an arbitrary centrality index based on distances. This actually defines\n",
        "a new dominance relation among nodes. In fact, we can go a step further. It does\n",
        "not really matter in which order we aggregate the distances, the result will always be the same.\n",
        "Hence, we can permute all relations of a single node without affecting the result.\n",
        "A convenient choice of permutation is simply to reorder all relations in descending\n",
        "order. Afterwards, we can compute the dominance relations as above. (More formal details on these dominance relations can be found in [this article](https://journals.sagepub.com/doi/abs/10.1177/2059799116630650).)\n",
        "\n",
        "We can compute this new dominance relation using the function `positional_dominance()`.\n",
        "The `benefit` parameter is set to `FALSE` since large distances are not beneficial for\n",
        "a node to have. Setting `map=TRUE` invokes the above mentioned reordering. For comparison,\n",
        "we also compute neighborhood-inclusion again.\n",
        "```{r positional_dominance}\n",
        "P <- neighborhood_inclusion(g1)\n",
        "D <- g1 |> \n",
        "  indirect_relations(type=\"dist_sp\") |> \n",
        "  positional_dominance(benefit=FALSE,map=TRUE)\n",
        "\n",
        "c(\"neighborhood-inclusion\"=comparable_pairs(P),\"distance dominance\"=comparable_pairs(D))\n",
        "```\n",
        "By fixing our relation of interest to distances and allowing reordering of relations, we \n",
        "went from only 16% of comparable pairs to 87%! Hence, no matter what index based on distance we use,\n",
        "results will always be very similar. As a sanity check, we can verify that all distance based indices from above preserve the dominance relations.\n",
        "```{r pdpreserved}\n",
        "c(\"classic\"=is_preserved(D,c_C),\"harmonic\"=is_preserved(D,c_HC),\"residual\"=is_preserved(D,c_RC))\n",
        "```\n",
        "\n",
        "# Partial Centrality\n",
        "\n",
        "By now, we should have understood that there are various kinds of partial rankings in networks,\n",
        "which form the basis of centrality. Indices extend these partial rankings into **one** possible ranking,\n",
        "but, as we will see later, there might be hundreds of thousands of possible rankings. And hence, hundreds of \n",
        "thousands of indices that produce these rankings. Instead of inventing hundreds of thousands of\n",
        "indices, why not just study the partial rankings? Or why not be extremely bold, and try to \n",
        "analyse **all** possible rankings at once? \n",
        "\n",
        "In this section, we consider the former question, by introducing *rank intervals*. A rank interval\n",
        "of a node is the set of ranks a node can have in any ranking that extends a given partial ranking.\n",
        "Let us consider two extreme cases. A node that is neither dominated nor dominates any other node can potentially\n",
        "have any rank. So its rank interval is $[1,n]$. (We use the convention, that $n$ is the top rank and $1$ the lowest possible rank).\n",
        "On the other hand, if a node dominates all other nodes, it can only be ranked on the top. So its rank interval is just a point.\n",
        "\n",
        "`netrankr` includes the function `rank_intervals()` which returns the rank intervals for all nodes in the network.\n",
        "A visual representation of the intervals can be obtained by using the `plot()` function, as done below for the \n",
        "first example network and neighborhood-inclusion as partial ranking input. We also included an optional `data.frame`\n",
        "containing centrality scores of five indices. \n",
        "```{r rank_intervals_all}\n",
        "cent_scores <- data.frame(\n",
        "   degree=degree(g1),\n",
        "   betweenness=betweenness(g1),\n",
        "   closeness=closeness(g1),\n",
        "   eigen=eigen_centrality(g1)$vector,\n",
        "   subgraph=subgraph.centrality(g1))\n",
        "\n",
        "plot(rank_intervals(P),cent.df = cent_scores)\n",
        "```\n",
        "The rank intervals are extremely big for this network. Node 10, for instance can take any possible rank.\n",
        "The most constraint interval is that of node 1, containing 6 possible ranks. The rank intervals can be interpreted as\n",
        "a sort of confidence interval for centrality. The larger the interval, the less explanatory power\n",
        "a single index may have Again, consider Node 10. It is the most central node according to subgraph centrality, but ranks very low in betweenness.\n",
        "\n",
        "We have learned that we can extend neighborhood-inclusion by choosing a relation of interest as \n",
        "basis for our analysis. For the example network, we considered distances.\n",
        "The below figure shows the resulting rank intervals.\n",
        "```{r rank_intervals_dist}\n",
        "cent_scores <- data.frame(\n",
        "   classic=c_C,\n",
        "   harmonic=c_HC,\n",
        "   residual=c_RC)\n",
        "\n",
        "plot(rank_intervals(D),cent.df = cent_scores)\n",
        "```\n",
        "Notice how much smaller they got. The intervals of node 1 and 2 even collapse into a single point.\n",
        "They will thus always be ranked at the bottom in any distance based centrality ranking.\n",
        "\n",
        "Rank intervals are a convenient choice to assess the possibilities of rankings in a network.\n",
        "It is important to understand, though, that the ranks in each interval do not occur with\n",
        "uniform probability. A rank interval $[6,7]$ does not mean that the node is ranked 6th in 50%\n",
        "of all possible rankings. We address the *rank probabilities* in the next section.\n",
        "\n",
        "## Probabilistic Centrality\n",
        "\n",
        "A node ranking can be defined as a mapping \n",
        "$$rk: V \\to \\{1,\\ldots,n\\},$$\n",
        "where we use the convention that $u$ is the top ranked node if $rk(u)=n$ and the \n",
        "bottom ranked one if $rk(u)=1$. The set of all possible rankings can then be characterized as\n",
        "$$\n",
        "\\mathcal{R}(\\leq)=\\{rk:V \\to \\{1,\\ldots,n\\}\\; : \\; u\\leq v \\implies rk(u)\\leq rk(v)\\}.\n",
        "$$\n",
        "This set contains all rankings that could be obtained for centrality indices that preserve the\n",
        "partial ranking of a dominance relation \"$\\leq$\".\n",
        "\n",
        "Once $\\mathcal{R}(\\leq)$ is calculated, it can be used for a probabilistic assessment of centrality,\n",
        "analyzing all possible rankings at once. Examples include *relative rank probabilities*\n",
        "(How likely is it, that a node $u$ is more central than another node $v$?) or\n",
        "*expected ranks* (How central do we expect a node $u$ to be).  \n",
        "\n",
        "`netrankr` includes the function `exact_rank_prob()`, which helps to answer the above posted questions.\n",
        "We stick with our small example network and apply the function to both, neighborhood-inclusion\n",
        "and dominance based on distances.\n",
        "```{r probs}\n",
        "probNI <- exact_rank_prob(P) \n",
        "probD  <- exact_rank_prob(D)\n",
        "```\n",
        "\n",
        "The function returns a large list of different outputs, which we discuss in the following.\n",
        "The number of possible rankings is stored in `lin.ext`.\n",
        "```{r no_of_rks}\n",
        "c(\"neighborhood-inclusion\"=probNI$lin.ext,\"distances\"=probD$lin.ext)\n",
        "```\n",
        "So, for this tiny network, there are still more than 700,000 possibilities to rank the nodes differently.\n",
        "If we restrict ourselves to distances, we end up with only 20.\n",
        "\n",
        "The rank probabilities (for example how likely is it that node $u$ is ranked on top?)\n",
        "are stored in the matrix `rank.prob`. We here focus on the probability to be the most central node.\n",
        "\n",
        "```{r rank_probsNI}\n",
        "top_rank <- ncol(probNI$rank.prob)\n",
        "probNI$rank.prob[,11]\n",
        "```\n",
        "Node 5 and 11 have the highest probability to be the most central node. You can think of the\n",
        "probabilities as follows: If we would apply thousands of indices to the network, in 16% of the cases\n",
        "will node 5 be the most central node. \n",
        "\n",
        "Relative rank probabilities (How likely is it that $u$ is less central than $v$?) are stored in the matrix `relative.rank`.\n",
        "```{r relranksNI}\n",
        "round(probNI$relative.rank,2)\n",
        "```\n",
        "For example, the probability that node 2 is less central than node 1 is $0.33$.\n",
        "The closer a probability to $0.5$ (see node 11 and 5), the less reason exists to put either node on top of the other.\n",
        "\n",
        "The last return values of interest are the expected ranks and the standard deviation in `expected.rank` and `rank.spread`.\n",
        "The expected ranks can be seen as a sort of baseline ranking. Applying hundreds of random indices, this is the ranking we could expect to get on average. \n",
        "```{r exprksNI}\n",
        "exp_rk <- round(probNI$expected.rank,2)\n",
        "sd_rk <- round(probNI$rank.spread,2)\n",
        "\n",
        "exp_rk\n",
        "sd_rk\n",
        "```\n",
        "\n",
        "The standard deviations are quite large for neighborhood-inclusion, which was to be expected from the big rank\n",
        "intervals. Below, we calculate the expected ranks for the distance based dominance.\n",
        "\n",
        "```{r exprksD}\n",
        "exp_rk <- round(probD$expected.rank,2)\n",
        "sd_rk <- round(probD$rank.spread,2)\n",
        "\n",
        "exp_rk\n",
        "sd_rk\n",
        "```\n",
        "\n",
        "\n",
        "As a word of warning: The problem of finding all possible rankings for a partial ranking is \n",
        "computationally a hard problem. So it is advisable to use `exact_rank_prob()` only for small \n",
        "networks. Some benchmark results and approximation methods for larger networks can be found [here](http://netrankr.schochastics.net/articles/benchmarks.html).\n",
        "\n",
        "## Summary\n",
        "\n",
        "To date, network centrality is nothing more than the application of indices:\n",
        "\n",
        "![](\"diagram_old.png\")\n",
        "\n",
        "The only degree of freedom is the choice of index and it is hard to justify choices\n",
        "without resorting to data-driven reasoning, as in \"We used betweenness because it worked best\".\n",
        "\n",
        "The introduced neighborhood-inclusion and more specific\n",
        "dominance concepts allow for additional ways of analyzing centrality in networks,\n",
        "described in this superficial diagram.\n",
        "\n",
        "![](\"diagram_new.png\")\n",
        "\n",
        "Any centrality analysis starts with identifying the *relation of interest*, which \n",
        "replaces the choice of index. The relation of interest is usually some graph-theoretic\n",
        "property (e.g. distances) that we assume to be indicative for centrality. The relations\n",
        "of a node to all others is called its *position*. The aggregation of the relations leads \n",
        "to the definition of indices, hence the usual centrality concept. However, positions can also\n",
        "be compared via *positional dominance*, the dominance relation introduced in this post, leading to partial centrality rankings and\n",
        "the option to calculate probabilistic centrality rankings. \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}